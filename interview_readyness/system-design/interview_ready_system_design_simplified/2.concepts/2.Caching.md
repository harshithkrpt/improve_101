# âš¡ï¸ Caching in Distributed Systems

Caching is a technique used to store frequently accessed data in a fast-access layer to reduce latency, avoid expensive operations, and improve system performance.

---

## âœ… Benefits of a Cache

- **ğŸš€ Saves Network Calls**  
  Frequently accessed remote data can be stored locally to reduce latency.

- **ğŸ” Avoids Repeated Computations**  
  Computation-heavy results (e.g., rendered templates, complex queries) can be reused.

- **ğŸ—ƒï¸ Reduces Database Load**  
  Relieves backend databases by answering common queries from the cache.

---

## âŒ Drawbacks of a Cache

- **ğŸ’° Can Be Expensive**  
  High-performance memory like RAM or SSDs used in caching increases cost.

- **ğŸ”„ Potential Thrashing**  
  If the cache size is small or the eviction policy is suboptimal, data might be repeatedly evicted and reloaded.

- **Eventual Consistency**
  That is based on the policy of the write the consistency is varied and can have stale data.

---

## ğŸ“œ Cache Eviction Policies

### 1. **LRU (Least Recently Used)**
- Removes the **least recently accessed** item when the cache is full.
- Assumes that recently used items are likely to be used again soon.

### 2. **LFU (Least Frequently Used)**
- Removes the **least frequently accessed** item.
- Better for scenarios where access frequency is a better predictor than recency.

---

## ğŸ§  Additional Concepts

- **TTL (Time to Live)**: Automatically expires cache entries after a time.
- **Write-Through Cache**: Writes to both cache and DB simultaneously.
- **Write-Back Cache**: Writes only to cache and pushes to DB later (asynchronously).
- **Read-Through Cache**: Automatically fetches from DB if cache miss occurs.
- **Cache Invalidation**: Mechanism to remove or update stale data.

---

## ğŸ§¾ Summary

| Aspect | Benefit |
|--------|---------|
| **Performance** | Reduces latency and improves response times |
| **Efficiency** | Lowers database load and resource usage |
| **Scalability** | Handles frequent reads efficiently |

Use caching wisely depending on access patterns, data volatility, and system constraints.

# ğŸ—‚ï¸ Cache Policy vs Eviction Policy

In caching systems, **cache policies** define how data is managed, and **eviction policies** determine which data to remove when the cache is full.

---

## ğŸ“¦ Cache Policy

Cache policy defines **how and when** data is loaded into and removed from the cache.

### Common Cache Strategies:

- **Read-Through Cache**  
  On a cache miss, the system reads from the database and populates the cache automatically.

- **Write-Through Cache**  
  Writes go to both the cache and the backing store (database) at the same time.

- **Write-Back (Write-Behind) Cache**  
  Writes go to the cache first, and the database is updated asynchronously later.

- **Refresh-Ahead Cache**  
  Periodically refreshes cache entries before they expire to avoid cache misses.

- **Cache Aside (Lazy Loading)**  
  The application code manually loads data into the cache on a miss and updates the cache after write operations.

---

## ğŸ§¹ Eviction Policy

Eviction policy determines **which item to remove** from the cache when it exceeds its memory/storage limit.

### Common Eviction Strategies:

- **LRU (Least Recently Used)**  
  Evicts the item that was accessed least recently.

- **LFU (Least Frequently Used)**  
  Evicts the item accessed the fewest number of times.

- **FIFO (First In, First Out)**  
  Evicts the oldest item i nserted into the cache.

- **MRU (Most Recently Used)**  
  Evicts the most recently used item (used in specific scenarios like stack-based caching).

- **Random Replacement**  
  Randomly evicts any item â€” simple but unpredictable.

---

## ğŸ§  Summary

| Policy Type       | Description                              |
|-------------------|------------------------------------------|
| **Cache Policy**  | Defines how data is added/updated in cache |
| **Eviction Policy** | Defines how data is removed when full    |

Choose cache & eviction policies based on your use case (read-heavy vs write-heavy, time sensitivity, etc.).


# ğŸ’¾ Write-Back Cache Policies

**Write-Back Cache** (also known as **Write-Behind**) is a caching strategy where data is first written to the cache, and the write to the underlying data store (e.g., database) happens **asynchronously**.

This improves write performance but introduces complexity in consistency and durability.

---

## ğŸ” Write-Back Policy Types

### 1. â±ï¸ TTL-Based (Time-To-Live Based)

- Data is written back to the main store **after a fixed time interval** (e.g., every 10 seconds).
- Useful for batching writes.
- Can reduce DB load but might lose data on crashes if not persisted.

**Example:**  
```text
Write to DB every 30 seconds after data is cached.
```

### 2. âš¡ Event-Based

- The write-back is triggered by specific **events** such as:
  - Cache eviction
  - User-defined events (e.g., save, logout)
  - Scheduled flush events

- Offers more control and avoids stale data on certain operations.

**Example:**  
```text
Flush cache to DB on user logout or session end.
```

### 3. ğŸ”„ Replacement-Based

- Data is written back **only when it is evicted** from the cache (due to LRU, LFU, etc.).
- Efficient but **risky**: if cache crashes before eviction, data may be lost.

**Example:**  
```text
Evict least recently used item and write it to DB during eviction.
```

---

## âš ï¸ Trade-Offs of Write-Back Caching

| Pros                           | Cons                             |
|--------------------------------|----------------------------------|
| Fast write performance         | Risk of data loss on crash       |
| Reduces database write load    | Harder to implement correctly    |
| Enables write batching         | Data is not immediately durable  |

---

## ğŸ§  Summary

| Policy Type        | Trigger                            | Use Case                              |
|--------------------|-------------------------------------|----------------------------------------|
| **TTL-Based**      | Time expiration                     | Periodic sync, non-critical writes     |
| **Event-Based**    | App or system event                 | Fine-grained control, user-driven sync |
| **Replacement-Based** | Eviction from cache             | Memory-constrained systems             |

Choose based on durability needs, write frequency, and system tolerance for delayed persistence.