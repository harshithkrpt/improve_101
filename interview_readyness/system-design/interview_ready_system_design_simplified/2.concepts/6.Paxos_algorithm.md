# ğŸ“œ Paxos Algorithm â€“ In-depth Notes

## ğŸ§  What is Paxos?
Paxos is a **consensus algorithm** used in distributed systems to agree on a single value (or sequence of values), even in the presence of failures and unreliable communication.

It ensures:
- **Safety** (no two nodes decide differently)
- **Liveness** (eventually, a decision is made)

---

## ğŸ“Œ Key Concepts

### ğŸ—³ï¸ Consensus
- Paxos aims to achieve **consensus** among a group of nodes.
- It requires a **majority agreement**: more than half of the nodes must agree on a value for it to be chosen.
- This ensures that even with node failures or message delays, consistency can be preserved.

### ğŸŒ Distributed Nature
- Paxos is designed for **distributed environments**:
  - Nodes may **crash**
  - **Messages can be lost or delayed**
  - No **global clock** or reliable failure detection
- Despite these challenges, Paxos guarantees **eventual agreement**.

### âš™ï¸ Use Cases
- Paxos is used in production systems for **distributed locking**, **leader election**, and **replicated logs**.
  - ğŸ“¦ **Google Chubby** â€“ distributed lock service
  - ğŸ§­ **Apache Zookeeper** (in earlier concepts)
  - â˜ï¸ **Microsoft Azure Storage**
- Often serves as a building block for higher-level distributed protocols.

### ğŸ“ˆ Importance
- Distributed consensus is one of the hardest problems in system design.
- Failures, race conditions, and network partitions make agreement difficult.
- Paxos addresses this with a **fault-tolerant, majority-based** voting system.

### ğŸ“š Prerequisites for Understanding Paxos
> Recommended by experts like Gaurav Sen for mastering distributed consensus:
- **Data consistency models** (eventual, strong, causal)
- **Isolation levels** (e.g., serializability, snapshot)
- **Quorum-based reads/writes**
- **Two-phase commit (2PC)** and why it can block
- **CAP theorem**

---

## ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Roles in Paxos
Paxos defines 3 main roles (a node can play multiple):

| Role       | Description |
|------------|-------------|
| **Proposer** | Suggests a value |
| **Acceptor** | Votes to accept proposals |
| **Learner**  | Learns the chosen value |

---

## ğŸ” Basic (Single-Decree) Paxos Protocol

### 1. **Prepare Phase**
- Proposer selects a unique proposal number `n`
- Sends: `Prepare(n)` to a majority of Acceptors

### 2. **Promise Phase**
- Acceptors respond to `Prepare(n)` if `n` > all previous promises
- They promise not to accept older proposals and return any previously accepted proposal `(n', v')`
- Response: `Promise(n, n', v')`

### 3. **Accept Phase**
- Proposer chooses value:
  - If any Acceptors responded with past proposals, it selects the one with the highest `n'`
  - Else, it chooses its own value
- Sends: `Accept(n, v)` to a majority

### 4. **Accepted Phase**
- Acceptors accept `(n, v)` if they promised `n`
- They send: `Accepted(n, v)` to all Learners

### 5. **Learn Phase**
- Learners wait for a majority of `Accepted(n, v)`
- Once received, `v` is considered **chosen**

---

## âœ… Paxos Guarantees
- **Consistency**: No two learners ever choose different values
- **Fault-tolerance**: Works with failures, as long as a **majority quorum** is available
- **No split-brain**: Conflicting values are never chosen

---

## ğŸ”§ Paxos Requirements
- **Unique proposal numbers**: typically generated using (proposer_id, counter)
- **Quorum intersection**: ensures that any two majorities have at least one common node

---

## ğŸ§  Multi-Paxos
Paxos for multiple values (replicated logs):

- **Leader election** is used to minimize the overhead of Prepare phases
- Once elected, the leader can directly propose values (like in Raft)
- Used for **state replication**, **sequencing operations**, or **primary-backup** systems

---

## ğŸ”„ Reconfiguration in Paxos
- Changing Acceptors or Quorum:
  1. Run a consensus to agree on a new configuration
  2. Start using it in the next Paxos instance

---

## ğŸ“Š Pros and Cons

### âœ… Pros:
- Proven safety even in the harshest distributed conditions
- Does not rely on a central coordinator
- Fault-tolerant via majority-based decision

### âŒ Cons:
- Complex to implement and understand
- Slower compared to simpler consensus mechanisms (like Raft)
- Failure recovery and leader change handling are tricky

---

## ğŸ” Paxos vs Raft
| Feature           | Paxos                              | Raft                              |
|------------------|-------------------------------------|------------------------------------|
| Understandability | Hard                               | Easier and more structured         |
| Leader            | Optional (used in Multi-Paxos)     | Always required                    |
| Performance       | Multi-Paxos optimization            | Built-in leader-based optimization |
| Use in Practice   | Google Chubby, Azure, etc.          | etcd, Consul, Docker Swarm         |

---

## ğŸ› ï¸ Real-World Systems Using Paxos
- âœ… **Google Chubby** â€“ Coordination and lock service
- âœ… **Microsoft Azure Storage**
- âœ… **Spanner** â€“ Uses Paxos-like mechanisms with global clocks
- âœ… **Zookeeper** (originally based on Paxos ideas)

---

## ğŸ§ª Summary

- Paxos achieves **majority-based consensus** in unreliable distributed systems
- Designed for safety first, with liveness if the network stabilizes
- Serves as the foundation for many critical infrastructure systems

---

## ğŸ“˜ Further Reading & Resources
- ğŸ“„ [Paxos Made Simple â€“ Leslie Lamport](https://lamport.azurewebsites.net/pubs/paxos-simple.pdf)
- ğŸ¥ [Gaurav Sen â€“ Paxos Explained](https://www.youtube.com/watch?v=JEpsBgQfBRU)
- ğŸ“– Distributed Systems by Maarten van Steen & Andrew Tanenbaum

